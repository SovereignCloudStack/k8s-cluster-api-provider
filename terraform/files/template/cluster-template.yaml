# See https://raw.githubusercontent.com/kubernetes-sigs/cluster-api-provider-openstack/main/templates/cluster-template-external-cloud-provider.yaml
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: ${CLUSTER_NAME}
spec:
  clusterNetwork:
    pods:
      cidrBlocks: ["${POD_CIDR}"]
    services:
      cidrBlocks: ["${SERVICE_CIDR}"]
    serviceDomain: "cluster.local"
  infrastructureRef:
    # apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
    kind: OpenStackCluster
    name: ${CLUSTER_NAME}
  controlPlaneRef:
    kind: KubeadmControlPlane
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    name: ${CLUSTER_NAME}-control-plane
---
# apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
kind: OpenStackCluster
metadata:
  name: ${CLUSTER_NAME}
spec:
  cloudName: ${OPENSTACK_CLOUD}
  identityRef:
    name: ${CLUSTER_NAME}-cloud-config
    kind: Secret
  # managedAPIServerLoadBalancer: true
  apiServerLoadBalancer:
    enabled: true
  managedSecurityGroups: true
  nodeCidr: ${NODE_CIDR}
  dnsNameservers: ${OPENSTACK_DNS_NAMESERVERS}
  externalNetworkId: ${OPENSTACK_EXTERNAL_NETWORK_ID}
---
kind: KubeadmControlPlane
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
metadata:
  name: "${CLUSTER_NAME}-control-plane"
spec:
  replicas: ${CONTROL_PLANE_MACHINE_COUNT}
  machineTemplate:
    infrastructureRef:
      kind: OpenStackMachineTemplate
      # apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
      name: "${PREFIX}-${CLUSTER_NAME}-control-plane-${CONTROL_PLANE_MACHINE_GEN}"
  kubeadmConfigSpec:
    initConfiguration:
      nodeRegistration:
        name: '{{ local_hostname }}'
        kubeletExtraArgs:
          cloud-provider: external
    clusterConfiguration:
      imageRepository: registry.k8s.io
      dns:
        imageRepository: registry.k8s.io/coredns
      apiServer:
        extraArgs:
          cloud-provider: external
      controllerManager:
        extraArgs:
          cloud-provider: external
      etcd:
        local:
          dataDir: /var/lib/etcd
          extraArgs:
            heartbeat-interval: "250"
            election-timeout: "2500"
            snapshot-count: "6400"
            auto-compaction-mode: periodic
            auto-compaction-retention: 8h
    joinConfiguration:
      nodeRegistration:
        name: '{{ local_hostname }}'
        kubeletExtraArgs:
          cloud-provider: external
    files:
      - path: /root/etcd-defrag.sh
        owner: "root:root"
        permissions: "0755"
        content: |
          #!/bin/bash
          # Defragment & backup & trim script for SCS k8s-cluster-api-provider etcd cluster.
          #
          # Script exits without any defragmentation/backup/trim action if:
          #  - It is executed on non leader etcd member
          #  - It is executed on etcd cluster with some unhealthy member
          #  - It is executed on single member etcd cluster
          # Conditions above could be skipped and the script execution could be forced by the optional arguments:
          #  - `--force-single`
          #  - `--force-unhealthy`
          #  - `--force-nonleader`
          #
          # The defragmentation on the etcd cluster is executed as follows:
          #  - Defragment the non leader etcd members first
          #  - Change the leadership to the randomly selected and defragmentation completed etcd member
          #  - Defragment the local (ex-leader) etcd member
          # Script then backup & trim local (ex-leader) etcd member
          #
          # Usage: etcd-defrag.sh [--force-single] [--force-unhealthy] [--force-nonleader]

          export LOG_DIR=/var/log
          export ETCDCTL_API=3
          ETCDCTL="etcdctl --cert /etc/kubernetes/pki/etcd/peer.crt --key /etc/kubernetes/pki/etcd/peer.key --cacert /etc/kubernetes/pki/etcd/ca.crt"

          while :
          do
              case "$1" in
              --force-single)
                FORCE_SINGLE=1 ;;
              --force-unhealthy)
                FORCE_UNHEALTHY=1 ;;
              --force-nonleader)
                FORCE_NONLEADER=1 ;;
              *) break;;
              esac
              shift
          done

          if test "$($ETCDCTL endpoint status | cut -d ',' -f 5 | tr -d [:blank:])" = "false"; then
            if test "$FORCE_NONLEADER" = "1"; then
              echo "Warning: forced defragmentation on non leader!"
            else
              echo "Exit on non leader (use --force-nonleader optional argument if you want to force defragmentation on non leader)"
              exit 0
            fi
          fi

          # Check health of all etcd members
          while read MEMBER; do
            if test "$(echo "$MEMBER" | cut -d ' ' -f 3 | tr -d [:])" != "healthy"; then
              if test "$FORCE_UNHEALTHY" = "1"; then
                echo "Warning: forced defragmentation on unhealthy etcd member $(echo "$MEMBER" | cut -d ' ' -f 1 | tr -d [:])!"
              else
                echo "Exit on unhealthy etcd member $(echo "$MEMBER" | cut -d ' ' -f 1 | tr -d [:]) (use --force-unhealthy optional argument if you want to force defragmentation on unhealthy etcd member)"
                exit 0
              fi
            fi
          done < <($ETCDCTL endpoint health --cluster)

          # Get all etcd members with their endpoints, IDs, and leader status
          declare -a MEMBERS
          declare -i MEMBERS_LENGTH=0
          while read MEMBER; do
            MEMBERS+=( "$MEMBER" )
            ((MEMBERS_LENGTH++))
          done < <($ETCDCTL endpoint status --cluster)

          if test "$FORCE" != "1" -a "$MEMBERS_LENGTH" = 1; then
            if test "$FORCE_SINGLE" = "1"; then
              echo "Warning: forced defragmentation on single member etcd!"
            else
              echo "Exit on single member etcd (use --force-single optional argument if you want to force defragmentation on single member etcd)"
              exit 0
            fi
          fi

          # Skip step-by-step defragmentation if the defragmentation on single member etcd is forced
          if test -z "$FORCE_SINGLE"; then
            declare -a NON_LEADER_IDS
            declare -i NON_LEADER_IDS_LENGTH=0
            for MEMBER in "$${MEMBERS[@]}"; do
              # Get member ID, endpoint, and leader status
              MEMBER_ENDPOINT=$(echo "$MEMBER" | cut -d ',' -f 1 | tr -d [:blank:])
              MEMBER_ID=$(echo "$MEMBER" | cut -d ',' -f 2 | tr -d [:blank:])
              MEMBER_IS_LEADER=$(echo "$MEMBER" | cut -d ',' -f 5 | tr -d [:blank:])
              # Defragment if $MEMBER is not the leader
              if test "$MEMBER_IS_LEADER" == "false"; then
                echo "Etcd member $${MEMBER_ENDPOINT} is not the leader, let's defrag it!"
                $ETCDCTL --endpoints="$MEMBER_ENDPOINT" defrag
                NON_LEADER_IDS+=( "$MEMBER_ID" )
                ((NON_LEADER_IDS_LENGTH++))
              fi
            done

            # Randomly pick an ID from non-leader IDs and make it a leader
            RANDOM_NON_LEADER_ID=$${NON_LEADER_IDS[ $(($RANDOM % "$NON_LEADER_IDS_LENGTH")) ]}
            echo "Member $${RANDOM_NON_LEADER_ID} is becoming the leader"
            $ETCDCTL move-leader $RANDOM_NON_LEADER_ID
          fi

          # Defrag this ex-leader etcd member
          sync
          sleep 2
          $ETCDCTL defrag

          # Backup&trim this ex-leader etcd member
          sleep 3
          $ETCDCTL snapshot save /root/etcd-backup
          chmod 0600 /root/etcd-backup
          xz -f /root/etcd-backup
          fstrim -v /var/lib/etcd
      - path: /etc/systemd/system/etcd-defrag.service
        owner: "root:root"
        permissions: "0644"
        content: |
          [Unit]
          Description=Run etcdctl defrag
          Documentation=https://etcd.io/docs/v3.5/op-guide/maintenance/#defragmentation
          After=network.target

          [Service]
          Type=oneshot
          #Environment="LOG_DIR=/var/log"
          #Environment="ETCDCTL_API=3"
          ExecStart=/root/etcd-defrag.sh
          Nice=19
          IOSchedulingClass=idle
          IOSchedulingPriority=7

          [Install]
          WantedBy=timers.target
      - path: /etc/systemd/system/etcd-defrag.timer
        owner: "root:root"
        permissions: "0644"
        content: |
          [Unit]
          Description=Run etcd-defrag.service every day
          After=network.target

          [Timer]
          OnCalendar=*-*-* 02:30:00

          [Install]
          WantedBy=timers.target
      - path: /root/tweak-kubeapi-memlimit.sh
        owner: root:root
        permissions: "0755"
        content: |
          #!/bin/bash
          MEM=$(free -m | grep '^Mem:' | awk '{print $2;}')
          sed -i "/^ *requests:/i\      limits:\n        memory: $((32+3*$MEM/4))M" /etc/kubernetes/manifests/kube-apiserver.yaml
    postKubeadmCommands:
      - if test "${ETCD_UNSAFE_FS}" = "true"; then mount -o remount,barrier=0,commit=20 /; sed -i 's@errors=remount-ro@errors=remount-ro,barrier=0,commit=20@' /etc/fstab; fi
      - /root/tweak-kubeapi-memlimit.sh
      - sync; systemctl restart kubelet    # We should no longer need this
      - while test -z "$EPID"; do sleep 5; EPID=`pgrep etcd`; done; renice -10 $EPID; ionice -c2 -n0 -p $EPID
      - systemctl enable etcd-defrag.service
      - systemctl enable --now etcd-defrag.timer
    preKubeadmCommands:
      - DEBIAN_FRONTEND=noninteractive apt-get install -y apt-transport-https curl
      - curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
      - echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" > /etc/apt/sources.list.d/kubernetes.list
      - apt-get update -y
      - TRIMMED_KUBERNETES_VERSION=$(echo ${KUBERNETES_VERSION} | sed 's/\./\./g' | sed 's/^v//')
      - RESOLVED_KUBERNETES_VERSION=$(apt-cache policy kubelet | sed 's/\*\*\*//' | awk -v VERSION=$${TRIMMED_KUBERNETES_VERSION} '$1~ VERSION { print $1 }' | head -n1)
      - apt-get install -y ca-certificates socat jq ebtables apt-transport-https cloud-utils prips containerd kubelet=$${RESOLVED_KUBERNETES_VERSION} kubeadm=$${RESOLVED_KUBERNETES_VERSION} kubectl=$${RESOLVED_KUBERNETES_VERSION}
      # Allow to configure registry hosts in containerd
      - |
        cat <<EOT >> /etc/containerd/config.toml
          [plugins."io.containerd.grpc.v1.cri".registry]
            config_path = "/etc/containerd/certs.d"
        EOT
      - systemctl daemon-reload
      - systemctl restart containerd.service
      # Install etcdctl
      - ETCDCTL_VERSION=v3.5.9
      - curl -L https://github.com/coreos/etcd/releases/download/$${ETCDCTL_VERSION}/etcd-$${ETCDCTL_VERSION}-linux-amd64.tar.gz -o /tmp/etcd-$${ETCDCTL_VERSION}-linux-amd64.tar.gz
      - tar xzvf /tmp/etcd-$${ETCDCTL_VERSION}-linux-amd64.tar.gz -C /tmp/
      - sudo cp /tmp/etcd-$${ETCDCTL_VERSION}-linux-amd64/etcdctl /usr/local/bin/
      - rm -rf /tmp/etcd-$${ETCDCTL_VERSION}-linux-amd64 /tmp/etcd-$${ETCDCTL_VERSION}-linux-amd64.tar.gz
      # TODO: Detect local SSD and mkfs/mount /var/lib/etcd
  version: "${KUBERNETES_VERSION}"
---
# apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
kind: OpenStackMachineTemplate
metadata:
  name: ${PREFIX}-${CLUSTER_NAME}-control-plane-${CONTROL_PLANE_MACHINE_GEN}
spec:
  template:
    spec:
      flavor: ${OPENSTACK_CONTROL_PLANE_MACHINE_FLAVOR}
      serverGroupID: ${OPENSTACK_SRVGRP_CONTROLLER}
      image: ${OPENSTACK_IMAGE_NAME}
      sshKeyName: ${OPENSTACK_SSH_KEY_NAME}
      cloudName: ${OPENSTACK_CLOUD}
      identityRef:
        name: ${CLUSTER_NAME}-cloud-config
        kind: Secret
      securityGroups:
        - name: ${PREFIX}-allow-ssh
        - name: ${PREFIX}-allow-icmp
        - name: ${PREFIX}-${CLUSTER_NAME}-cilium
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  name: "${PREFIX}-${CLUSTER_NAME}-md-0-no1"
spec:
  clusterName: "${CLUSTER_NAME}"
  replicas: ${WORKER_MACHINE_COUNT}
  selector:
    matchLabels:
  template:
    spec:
      clusterName: "${CLUSTER_NAME}"
      version: "${KUBERNETES_VERSION}"
      failureDomain: ${OPENSTACK_FAILURE_DOMAIN}
      bootstrap:
        configRef:
          name: "${PREFIX}-${CLUSTER_NAME}-md-0-${WORKER_MACHINE_GEN}"
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
      infrastructureRef:
        name: "${PREFIX}-${CLUSTER_NAME}-md-0-${WORKER_MACHINE_GEN}"
        # apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
        kind: OpenStackMachineTemplate
---
# apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha6
kind: OpenStackMachineTemplate
metadata:
  name: ${PREFIX}-${CLUSTER_NAME}-md-0-${WORKER_MACHINE_GEN}
spec:
  template:
    spec:
      cloudName: ${OPENSTACK_CLOUD}
      identityRef:
        name: ${CLUSTER_NAME}-cloud-config
        kind: Secret
      flavor: ${OPENSTACK_NODE_MACHINE_FLAVOR}
      serverGroupID: ${OPENSTACK_SRVGRP_WORKER}
      image: ${OPENSTACK_IMAGE_NAME}
      sshKeyName: ${OPENSTACK_SSH_KEY_NAME}
      securityGroups:
        - name: ${PREFIX}-allow-ssh
        - name: ${PREFIX}-allow-icmp
        - name: ${PREFIX}-${CLUSTER_NAME}-cilium
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: ${PREFIX}-${CLUSTER_NAME}-md-0-${WORKER_MACHINE_GEN}
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          name: '{{ local_hostname }}'
          kubeletExtraArgs:
            cloud-provider: external
      preKubeadmCommands:
        - DEBIAN_FRONTEND=noninteractive apt-get install -y apt-transport-https curl
        - curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
        - echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" > /etc/apt/sources.list.d/kubernetes.list
        - apt-get update -y
        - TRIMMED_KUBERNETES_VERSION=$(echo ${KUBERNETES_VERSION} | sed 's/\./\./g' | sed 's/^v//')
        - RESOLVED_KUBERNETES_VERSION=$(apt-cache policy kubelet | sed 's/\*\*\*//' | awk -v VERSION=$${TRIMMED_KUBERNETES_VERSION} '$1~ VERSION { print $1 }' | head -n1)
        - apt-get install -y ca-certificates socat jq ebtables apt-transport-https cloud-utils prips containerd kubelet=$${RESOLVED_KUBERNETES_VERSION} kubeadm=$${RESOLVED_KUBERNETES_VERSION} kubectl=$${RESOLVED_KUBERNETES_VERSION}
        # Allow to configure registry hosts in containerd
        - |
          cat <<EOT >> /etc/containerd/config.toml
            [plugins."io.containerd.grpc.v1.cri".registry]
              config_path = "/etc/containerd/certs.d"
          EOT
        - systemctl daemon-reload
        - systemctl restart containerd.service
---
apiVersion: v1
kind: Secret
metadata:
  name: ${CLUSTER_NAME}-cloud-config
  labels:
    clusterctl.cluster.x-k8s.io/move: "true"
data:
  clouds.yaml: ${OPENSTACK_CLOUD_YAML_B64}
  cacert: ${OPENSTACK_CLOUD_CACERT_B64}
